{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy\n",
    "import pandas\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pandas.set_option('display.max_columns', 500)\n",
    "\n",
    "def read_data_as_data_frame():\n",
    "    with open('EnergyEfficiencyData.csv') as csv_file:\n",
    "        return pandas.DataFrame(csv.reader(csv_file, delimiter=','))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data - Clean data with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_invalid_value(data_frame, is_invalid, invalid_type):\n",
    "    if is_invalid.sum().sum() == 0: \n",
    "        print(f'Data does not contain any {invalid_type} value')\n",
    "    else:\n",
    "        print(f'Number of {invalid_type} value or missing value: ', is_invalid.sum().sum())\n",
    "        # drop any column contain null value\n",
    "        data_frame = data_frame.dropna(axis=1, how='any')\n",
    "        # drop any row contain null value\n",
    "        data_frame = data_frame.dropna(axis=0, how='any')\n",
    "    return data_frame\n",
    "\n",
    "def process_empty_string(data_frame):\n",
    "    # drop row with empty string\n",
    "    # did not use inplace=True to avoid overwriting the reference to it and avoid SettingWithCopyWarning\n",
    "    data_frame = data_frame.drop(data_frame[data_frame['Relative Compactness'] == ''].index)\n",
    "    data_frame = data_frame.drop(data_frame[data_frame['Wall Area'] == ''].index)\n",
    "    data_frame = data_frame.drop(data_frame[data_frame['Roof Area'] == ''].index)\n",
    "    data_frame = data_frame.drop(data_frame[data_frame['Surface'] == ''].index)\n",
    "    data_frame = data_frame.drop(data_frame[data_frame['Overall Height'] == ''].index)\n",
    "    data_frame = data_frame.drop(data_frame[data_frame['Orientation'] == ''].index)\n",
    "    data_frame = data_frame.drop(data_frame[data_frame['Glazing Area'] == ''].index)\n",
    "    data_frame = data_frame.drop(data_frame[data_frame['Glazing Area Distribution'] == ''].index)\n",
    "    data_frame = data_frame.drop(data_frame[data_frame['Heating Load'] == ''].index)\n",
    "    data_frame = data_frame.drop(data_frame[data_frame['Cooling Load'] == ''].index)\n",
    "    \n",
    "    return data_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data - format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(data_frame): \n",
    "    # convert all object(string) to number(float)\n",
    "    float_data_frame = data_frame.drop(['Orientation', 'Glazing Area Distribution'], axis=1).astype(float)\n",
    "    # convert integer column to integer\n",
    "    data_frame['Orientation'] = data_frame['Orientation'].astype(int)\n",
    "    data_frame['Glazing Area Distribution'] = data_frame['Glazing Area Distribution'].astype(int)\n",
    "\n",
    "    float_data_frame.insert(5, 'Orientation', data_frame['Orientation'], True)\n",
    "    float_data_frame.insert(7, 'Glazing Area Distribution', data_frame['Glazing Area Distribution'], True)\n",
    "\n",
    "    data_frame = float_data_frame\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data - Check and remove multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_multicollinearity(data_frame):\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "    x = data_frame.drop(['Heating Load', 'Cooling Load'], axis=1)\n",
    "\n",
    "    # drop columns with strong multicollinearity\n",
    "    x = x.drop(columns=['Wall Area', 'Roof Area', 'Surface'])\n",
    "    \n",
    "    # center the predictors by substracting the mean    \n",
    "    x = x.subtract(x.mean())\n",
    "    \n",
    "    vif_data = pandas.DataFrame()\n",
    "    vif_data['feature'] = x.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(x.values, i) for i in range(len(x.columns))]\n",
    "\n",
    "    if vif_data['VIF'][vif_data['VIF'] >= 10].count() == 0:\n",
    "        print('Data does not contain collinearity or multicollinearity between variables')\n",
    "    else:\n",
    "        print(vif_data)\n",
    "        print('Result suggests high collinearity or multicollinearity between variables')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_frame(data_frame):\n",
    "    # drop last 2 empty column, use inplace=True to increase readability\n",
    "    data_frame.drop([10, 11], axis=1, inplace=True)\n",
    "\n",
    "    # make first row as header by:\n",
    "    # 1. assign header with first row\n",
    "    data_frame.columns = data_frame.iloc[0]\n",
    "    # 2. remove first row\n",
    "    data_frame = data_frame[1:]\n",
    "\n",
    "    # rename column to readable attributes\n",
    "    data_frame.columns = ['Relative Compactness',\n",
    "                          'Surface',\n",
    "                          'Wall Area',\n",
    "                          'Roof Area',\n",
    "                          'Overall Height',\n",
    "                          'Orientation',\n",
    "                          'Glazing Area',\n",
    "                          'Glazing Area Distribution',\n",
    "                          'Heating Load',\n",
    "                          'Cooling Load']\n",
    "    \n",
    "    # check the data frame\n",
    "    print(data_frame.info())\n",
    "\n",
    "    # check if there is any nan value\n",
    "    data_frame = process_invalid_value(data_frame, data_frame.isna(), 'NaN')\n",
    "    # check if there is any null value\n",
    "    data_frame = process_invalid_value(data_frame, data_frame.isnull(), 'Null')\n",
    "    # check if there is any empty string\n",
    "    data_frame = process_empty_string(data_frame)\n",
    "    \n",
    "    # format data\n",
    "    data_frame = format_data(data_frame)\n",
    "    \n",
    "    # check collinearity and multicollinearity among vairables\n",
    "#     check_multicollinearity(data_frame)\n",
    "    data_frame = data_frame.drop(columns=['Wall Area', 'Roof Area', 'Surface'])\n",
    "\n",
    "    # check the data frame\n",
    "    print(data_frame.info())\n",
    "\n",
    "    return data_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_result(regression_model_cv, x_train, x_test, y_train, y_test, y_predict, regression_model_type):\n",
    "    print(regression_model_type + \" Grid Search CV Best Score {}\".format(regression_model_cv.best_score_))\n",
    "    print(regression_model_type + \" Grid Search CV Best Estimator {}\".format(regression_model_cv.best_estimator_))\n",
    "\n",
    "    print(regression_model_type + \" Grid Search CV Training Score {}\".\n",
    "          format(regression_model_cv.score(x_train, y_train)))\n",
    "    print(regression_model_type + \" Grid Search CV Testing Score {}\\n\".\n",
    "          format(regression_model_cv.score(x_test, y_test)))\n",
    "    \n",
    "    print(\"Adjusted r squared: {}\".\n",
    "          format(1 - (1-regression_model_cv.score(x_test, y_test))*(len(y_test)-1)/(len(y_test)-x_test.shape[1]-1)))\n",
    "    \n",
    "    return regression_model_cv.best_estimator_, regression_model_cv.score(x_train, y_train), regression_model_cv.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_regression(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    grid_parameters = {\n",
    "        'bootstrap': [True, False],\n",
    "        'max_depth': numpy.arange(start=10, stop=101, step=10),\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'n_estimators': numpy.arange(start=100, stop=501, step=100)\n",
    "    }\n",
    "\n",
    "    random_forest_cv = GridSearchCV(RandomForestRegressor(), grid_parameters, verbose=1, cv=5, n_jobs=-1)\n",
    "    random_forest_cv.fit(x_train, y_train)\n",
    "\n",
    "    y_predict = random_forest_cv.predict(x_test)\n",
    "\n",
    "    regression_model = 'Random Forest'\n",
    "\n",
    "    return print_regression_result(random_forest_cv, x_train, x_test, y_train, y_test, y_predict, regression_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    # parameters can be improved\n",
    "    grid_parameters = {\n",
    "        'normalize': [True, False],\n",
    "        'fit_intercept': [True, False],\n",
    "    }\n",
    "\n",
    "    linear_regression_cv = GridSearchCV(LinearRegression(), grid_parameters, verbose=1, cv=5, n_jobs=-1)\n",
    "    linear_regression_cv.fit(x_train, y_train)\n",
    "\n",
    "    y_predict = linear_regression_cv.predict(x_test)\n",
    "\n",
    "    regression_model = 'Linear Regression'\n",
    "\n",
    "    return print_regression_result(linear_regression_cv, x_train, x_test, y_train, y_test, y_predict, regression_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.linear_model import Ridge\n",
    "\n",
    "    # parameters can be improved\n",
    "    grid_parameters = {\n",
    "        'alpha': numpy.linspace(1, 21),\n",
    "        'normalize': [True, False],\n",
    "        'fit_intercept': [True, False],\n",
    "        'tol': [1e-5, 1e-4, 1e-3]\n",
    "    }\n",
    "\n",
    "    ridge_regression_cv = GridSearchCV(Ridge(), grid_parameters, verbose=1, cv=5, n_jobs=-1)\n",
    "    ridge_regression_cv.fit(x_train, y_train)\n",
    "\n",
    "    y_predict = ridge_regression_cv.predict(x_test)\n",
    "\n",
    "    regression_model = 'Ridge Regression'\n",
    "\n",
    "    return print_regression_result(ridge_regression_cv, x_train, x_test, y_train, y_test, y_predict, regression_model)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regression(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.linear_model import Lasso\n",
    "\n",
    "    # parameters can be improved\n",
    "    grid_parameters = {\n",
    "        'alpha': numpy.linspace(1, 21),\n",
    "        'normalize': [True, False],\n",
    "        'fit_intercept': [True, False],\n",
    "        'tol': [1e-5, 1e-4, 1e-3],\n",
    "        'max_iter': [10000, 20000, 30000],\n",
    "    }\n",
    "\n",
    "    lasso_regression_cv = GridSearchCV(Lasso(), grid_parameters, verbose=1, cv=5, n_jobs=-1)\n",
    "    lasso_regression_cv.fit(x_train, y_train)\n",
    "\n",
    "    y_predict = lasso_regression_cv.predict(x_test)\n",
    "\n",
    "    regression_model = 'Lasso Regression'\n",
    "\n",
    "    return print_regression_result(lasso_regression_cv, x_train, x_test, y_train, y_test, y_predict, regression_model)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def poission_regression(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.linear_model import PoissonRegressor\n",
    "    # parameters can be improved\n",
    "    grid_parameters = {\n",
    "        'alpha': numpy.linspace(1, 21),\n",
    "        'warm_start': [True, False],\n",
    "        'fit_intercept': [True, False],\n",
    "        'tol': [1e-5, 1e-4, 1e-3],\n",
    "        'max_iter': [10000, 20000, 30000],\n",
    "    }\n",
    "\n",
    "    poisson_regression_cv = GridSearchCV(PoissonRegressor(), grid_parameters, verbose=1, cv=5, n_jobs=-1)\n",
    "    poisson_regression_cv.fit(x_train, y_train)\n",
    "\n",
    "    y_predict = poisson_regression_cv.predict(x_test)\n",
    "\n",
    "    regression_model = 'Poisson Regression'\n",
    "\n",
    "    return print_regression_result(poisson_regression_cv, x_train, x_test, y_train, y_test, y_predict, regression_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_and_y(processed_data_frame):\n",
    "    x = processed_data_frame.drop(['Heating Load', 'Cooling Load'], axis=1)\n",
    "    y_heating = processed_data_frame['Heating Load']\n",
    "    y_cooling = processed_data_frame['Cooling Load']\n",
    "\n",
    "    return x, y_heating, y_cooling\n",
    "\n",
    "\n",
    "def train_set_test_set(x, y):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "    return train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate(results):\n",
    "    header = pandas.MultiIndex.from_product([['Heating','Cooling'],\n",
    "                                     ['Train Score','Test Score']],\n",
    "                                    names=['Energy Load','Result'])\n",
    "    idx = ['Ridge Regression', 'Lasso Regression', 'Linear Regression', 'Poisson Regression', 'Random Forest Regression']\n",
    "    result_df = pandas.DataFrame(index = idx, columns = header)\n",
    "    \n",
    "    random_forest, ridge, lasso, linear, poisson = results\n",
    "    \n",
    "    result_df.loc[:, ('Heating', 'Train Score')] = [ridge[0][1], lasso[0][1], linear[0][1], poisson[0][1], random_forest[0][1]]\n",
    "    result_df.loc[:, ('Heating', 'Test Score')] = [ ridge[0][2], lasso[0][2], linear[0][2], poisson[0][2], random_forest[0][2]]\n",
    "    result_df.loc[:, ('Cooling', 'Train Score')] = [ridge[1][1], lasso[1][1], linear[1][1], poisson[1][1], random_forest[1][1]]\n",
    "    result_df.loc[:, ('Cooling', 'Test Score')] = [ridge[1][2], lasso[1][2], linear[1][2], poisson[1][2], random_forest[1][2]]\n",
    "    \n",
    "    print(result_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296 entries, 1 to 1296\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   Relative Compactness       1296 non-null   object\n",
      " 1   Surface                    1296 non-null   object\n",
      " 2   Wall Area                  1296 non-null   object\n",
      " 3   Roof Area                  1296 non-null   object\n",
      " 4   Overall Height             1296 non-null   object\n",
      " 5   Orientation                1296 non-null   object\n",
      " 6   Glazing Area               1296 non-null   object\n",
      " 7   Glazing Area Distribution  1296 non-null   object\n",
      " 8   Heating Load               1296 non-null   object\n",
      " 9   Cooling Load               1296 non-null   object\n",
      "dtypes: object(10)\n",
      "memory usage: 101.4+ KB\n",
      "None\n",
      "Data does not contain any NaN value\n",
      "Data does not contain any Null value\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 768 entries, 1 to 768\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Relative Compactness       768 non-null    float64\n",
      " 1   Overall Height             768 non-null    float64\n",
      " 2   Orientation                768 non-null    int32  \n",
      " 3   Glazing Area               768 non-null    float64\n",
      " 4   Glazing Area Distribution  768 non-null    int32  \n",
      " 5   Heating Load               768 non-null    float64\n",
      " 6   Cooling Load               768 non-null    float64\n",
      "dtypes: float64(5), int32(2)\n",
      "memory usage: 42.0 KB\n",
      "None\n",
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed:    7.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Grid Search CV Best Score 0.8953519490481904\n",
      "Ridge Regression Grid Search CV Best Estimator Ridge(tol=1e-05)\n",
      "Ridge Regression Grid Search CV Training Score 0.9000822948435954\n",
      "Ridge Regression Grid Search CV Testing Score 0.928164338286723\n",
      "\n",
      "Adjusted r squared: 0.9257374578234365\n",
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Grid Search CV Best Score 0.8767831584084261\n",
      "Ridge Regression Grid Search CV Best Estimator Ridge(tol=1e-05)\n",
      "Ridge Regression Grid Search CV Training Score 0.880386840401586\n",
      "Ridge Regression Grid Search CV Testing Score 0.8883040634297871\n",
      "\n",
      "Adjusted r squared: 0.8845305520591717\n",
      "Fitting 5 folds for each of 1800 candidates, totalling 9000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 8838 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 9000 out of 9000 | elapsed:    9.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Grid Search CV Best Score 0.8400643820577038\n",
      "Lasso Regression Grid Search CV Best Estimator Lasso(max_iter=10000, tol=1e-05)\n",
      "Lasso Regression Grid Search CV Training Score 0.8448710527811366\n",
      "Lasso Regression Grid Search CV Testing Score 0.8434378503364446\n",
      "\n",
      "Adjusted r squared: 0.8381485885234866\n",
      "Fitting 5 folds for each of 1800 candidates, totalling 9000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 8838 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 9000 out of 9000 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Grid Search CV Best Score 0.8166124679756956\n",
      "Lasso Regression Grid Search CV Best Estimator Lasso(max_iter=10000, tol=1e-05)\n",
      "Lasso Regression Grid Search CV Training Score 0.8199159419922368\n",
      "Lasso Regression Grid Search CV Testing Score 0.8326050429755372\n",
      "\n",
      "Adjusted r squared: 0.826949807940927\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Linear Regression Grid Search CV Best Score 0.9042164564262677\n",
      "Linear Regression Grid Search CV Best Estimator LinearRegression(normalize=True)\n",
      "Linear Regression Grid Search CV Training Score 0.9066665486093857\n",
      "Linear Regression Grid Search CV Testing Score 0.9028902434398559\n",
      "\n",
      "Adjusted r squared: 0.8996095084209321\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Linear Regression Grid Search CV Best Score 0.8772062510206935\n",
      "Linear Regression Grid Search CV Best Estimator LinearRegression(normalize=True)\n",
      "Linear Regression Grid Search CV Training Score 0.8790934379756637\n",
      "Linear Regression Grid Search CV Testing Score 0.8940478008047992\n",
      "\n",
      "Adjusted r squared: 0.8904683346157721\n",
      "Fitting 5 folds for each of 1800 candidates, totalling 9000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2680 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 6680 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done 9000 out of 9000 | elapsed:   26.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisson Regression Grid Search CV Best Score 0.9160405753564682\n",
      "Poisson Regression Grid Search CV Best Estimator PoissonRegressor(max_iter=10000, tol=1e-05, warm_start=True)\n",
      "Poisson Regression Grid Search CV Training Score 0.9187779380519988\n",
      "Poisson Regression Grid Search CV Testing Score 0.8915224505437771\n",
      "\n",
      "Adjusted r squared: 0.8878576684675533\n",
      "Fitting 5 folds for each of 1800 candidates, totalling 9000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2680 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 6680 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 9000 out of 9000 | elapsed:   25.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisson Regression Grid Search CV Best Score 0.8941448387383278\n",
      "Poisson Regression Grid Search CV Best Estimator PoissonRegressor(max_iter=10000, tol=1e-05, warm_start=True)\n",
      "Poisson Regression Grid Search CV Training Score 0.8975495416617187\n",
      "Poisson Regression Grid Search CV Testing Score 0.8950873940697218\n",
      "\n",
      "Adjusted r squared: 0.89154304927478\n",
      "Fitting 5 folds for each of 1800 candidates, totalling 9000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=-1)]: Done 9000 out of 9000 | elapsed: 44.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Grid Search CV Best Score 0.9967447699024256\n",
      "Random Forest Grid Search CV Best Estimator RandomForestRegressor(max_depth=90, n_estimators=300)\n",
      "Random Forest Grid Search CV Training Score 0.9996176357977228\n",
      "Random Forest Grid Search CV Testing Score 0.9974240446585745\n",
      "\n",
      "Adjusted r squared: 0.997337019140283\n",
      "Fitting 5 folds for each of 1800 candidates, totalling 9000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 26.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=-1)]: Done 9000 out of 9000 | elapsed: 40.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Grid Search CV Best Score 0.9671955359926063\n",
      "Random Forest Grid Search CV Best Estimator RandomForestRegressor(max_depth=100)\n",
      "Random Forest Grid Search CV Training Score 0.995404942518749\n",
      "Random Forest Grid Search CV Testing Score 0.9775618910990339\n",
      "\n",
      "Adjusted r squared: 0.9768038468794067\n",
      "Energy Load                  Heating                Cooling           \n",
      "Result                   Train Score Test Score Train Score Test Score\n",
      "Ridge Regression            0.844871   0.843438    0.819916   0.832605\n",
      "Lasso Regression            0.906667   0.902890    0.879093   0.894048\n",
      "Linear Regression           0.918778   0.891522    0.897550   0.895087\n",
      "Poisson Regression          0.999618   0.997424    0.995405   0.977562\n",
      "Random Forest Regression    0.900082   0.928164    0.880387   0.888304\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # The dataset contains eight attributes (or features, denoted by X1...X8) and two responses (or outcomes,\n",
    "    # denoted by y1 and y2). The aim is to use the eight features to predict each of the two responses\n",
    "    \n",
    "    processed_data_frame = preprocess_data_frame(read_data_as_data_frame())\n",
    "    x, y_heating, y_cooling = get_x_and_y(processed_data_frame)\n",
    "\n",
    "    models = [ridge_regression, lasso_regression, linear_regression, poission_regression, random_forest_regression]\n",
    "    \n",
    "    def train_and_test(model):\n",
    "        x_train, x_test, y_heating_train, y_heating_test = train_set_test_set(x, y_heating)\n",
    "        best_heating = model(x_train, x_test, y_heating_train, y_heating_test)\n",
    "        \n",
    "        x_train, x_test, y_cooling_train, y_cooling_test = train_set_test_set(x, y_cooling)\n",
    "        best_cooling = model(x_train, x_test, y_cooling_train, y_cooling_test)\n",
    "                \n",
    "        return [best_heating, best_cooling]\n",
    "\n",
    "    results = list(map(train_and_test, models))\n",
    "    tabulate(results)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
